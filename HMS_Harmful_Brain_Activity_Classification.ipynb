{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voflvgIMTesA"
      },
      "source": [
        "# Initialize GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2024-02-07T20:26:00.957368Z",
          "iopub.status.busy": "2024-02-07T20:26:00.957086Z",
          "iopub.status.idle": "2024-02-07T20:26:00.967621Z",
          "shell.execute_reply": "2024-02-07T20:26:00.966688Z",
          "shell.execute_reply.started": "2024-02-07T20:26:00.957344Z"
        },
        "id": "3R8X6rCgTesA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os, gc\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1\"\n",
        "import tensorflow as tf\n",
        "import pandas as pd, numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print('TensorFlow version =',tf.__version__)\n",
        "\n",
        "# USE MULTIPLE GPUS\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if len(gpus)<=1:\n",
        "    strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\")\n",
        "    print(f'Using {len(gpus)} GPU')\n",
        "else:\n",
        "    strategy = tf.distribute.MirroredStrategy()\n",
        "    print(f'Using {len(gpus)} GPUs')\n",
        "\n",
        "# USE MIXED PRECISION\n",
        "MIX = True\n",
        "if MIX:\n",
        "    tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\n",
        "    print('Mixed precision enabled')\n",
        "else:\n",
        "    print('Using full precision')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swYAPibUTesA"
      },
      "source": [
        "# Load Train Data and Create Non-Overlapping Eeg Ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2024-02-07T20:26:00.968956Z",
          "iopub.status.busy": "2024-02-07T20:26:00.968659Z",
          "iopub.status.idle": "2024-02-07T20:26:01.269021Z",
          "shell.execute_reply": "2024-02-07T20:26:01.268051Z",
          "shell.execute_reply.started": "2024-02-07T20:26:00.968933Z"
        },
        "id": "7C1vv1FuTesB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/train.csv')\n",
        "TARGETS = df.columns[-6:]\n",
        "print('Train shape:', df.shape )\n",
        "print('Targets', list(TARGETS))\n",
        "\n",
        "###########\n",
        "\n",
        "train = df.groupby('eeg_id')[['spectrogram_id','spectrogram_label_offset_seconds']].agg(\n",
        "    {'spectrogram_id':'first','spectrogram_label_offset_seconds':'min'})\n",
        "train.columns = ['spec_id','min']\n",
        "\n",
        "tmp = df.groupby('eeg_id')[['spectrogram_id','spectrogram_label_offset_seconds']].agg(\n",
        "    {'spectrogram_label_offset_seconds':'max'})\n",
        "train['max'] = tmp\n",
        "\n",
        "tmp = df.groupby('eeg_id')[['eeg_label_offset_seconds']].agg('min')\n",
        "train['min_eeg'] = tmp\n",
        "\n",
        "tmp = df.groupby('eeg_id')[['eeg_label_offset_seconds']].agg('max')\n",
        "train['max_eeg'] = tmp\n",
        "\n",
        "tmp = df.groupby('eeg_id')[['patient_id']].agg('first')\n",
        "train['patient_id'] = tmp\n",
        "\n",
        "tmp = df.groupby('eeg_id')[TARGETS].agg('sum')\n",
        "for t in TARGETS:\n",
        "    train[t] = tmp[t].values\n",
        "\n",
        "y_data = train[TARGETS].values\n",
        "y_data = y_data / y_data.sum(axis=1,keepdims=True)\n",
        "train[TARGETS] = y_data\n",
        "\n",
        "tmp = df.groupby('eeg_id')[['expert_consensus']].agg('first')\n",
        "train['target'] = tmp\n",
        "\n",
        "train = train.reset_index()\n",
        "\n",
        "data_PATH = '/kaggle/input/hms-harmful-brain-activity-classification/'\n",
        "train['path_eeg']=train['eeg_id'].apply(lambda x: os.path.join(data_PATH,\"train_eegs/\"+str(x)+\".parquet\" ))\n",
        "\n",
        "print('Train non-overlapp eeg_id shape:', train.shape )\n",
        "train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feature engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As seen in this article[Metadata_notebook/Wavelets_for_EEG_Analysis.pdf],  wavelet analysis is wellsuited for EEG signals for describing time-localised event\n",
        "\n",
        "Therefore, I'm going to compute Scalograms & Spectrograms and use them as a features\n",
        "\n",
        "For that I decided to recreate the 4 LL, LP, RP, RL componants from the EEGs:\n",
        "\n",
        "![Spatialisation](Metadata_notebook/tileshop.jpg)\n",
        "![Spatialisation_2](Metadata_notebook/10-20-system-of-electrode-placement.png)\n",
        "\n",
        "The scalp is divided into 4 different regions for spectrogram construction: Left lateral (Fp1, F7, T3, T5, O10); right lateral (Fp2, F8, T4, T6, O2); left parasagittal (Fp1, F3, C3, P3, O1); right parasagittal (Fp2, F4, C4, P4, O2). Each spectrogram image has four panels: left lateral (LL), right lateral (RL), left parasagittal (LP), right parasagittal (RP).\n",
        "\n",
        "We extract each region from EEG data with this formula:\n",
        "\n",
        "```LL Spec = ( spec(Fp1 - F7) + spec(F7 - T3) + spec(T3 - T5) + spec(T5 - O1) )/4. ```\n",
        "\n",
        "```LL Scalo = ( scalo(Fp1 - F7) + scalo(F7 - T3) + scalo(T3 - T5) + scalo(T5 - O1) )/4. ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyy1yFc9ntnJ"
      },
      "source": [
        "# Scalograms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hpiJsjr7TesB"
      },
      "source": [
        "## Scalogram creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-07T20:27:08.979689Z",
          "iopub.status.idle": "2024-02-07T20:27:08.98005Z",
          "shell.execute_reply": "2024-02-07T20:27:08.979907Z",
          "shell.execute_reply.started": "2024-02-07T20:27:08.979893Z"
        },
        "id": "w672U-ZKTesB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import scipy, librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import pywt\n",
        "\n",
        "NAMES = ['LL','LP','RP','RR']\n",
        "\n",
        "FEATS = [['Fp1','F7','T3','T5','O1'],\n",
        "         ['Fp1','F3','C3','P3','O1'],\n",
        "         ['Fp2','F8','T4','T6','O2'],\n",
        "         ['Fp2','F4','C4','P4','O2']]\n",
        "\n",
        "\n",
        "def scalogram_from_eeg(parquet_path, eeg_offset, eeg_id, display=False):\n",
        "\n",
        "    # LOAD MIDDLE 8.533 SECONDS OF EEG SERIES\n",
        "    eeg = pd.read_parquet(parquet_path)\n",
        "\n",
        "    middle = eeg_offset*200+5000\n",
        "    eeg = eeg.iloc[middle-853:middle+853]\n",
        "\n",
        "    # VARIABLE TO HOLD SPECTROGRAM\n",
        "    img = np.zeros((128,512,4),dtype='float32')\n",
        "\n",
        "    signals = []\n",
        "    for k in range(4):\n",
        "        COLS = FEATS[k]\n",
        "\n",
        "        for kk in range(4):\n",
        "\n",
        "            # COMPUTE PAIR DIFFERENCES\n",
        "            x = eeg[COLS[kk]].values - eeg[COLS[kk+1]].values\n",
        "\n",
        "            # FILL NANS\n",
        "            m = np.nanmean(x)\n",
        "            if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n",
        "            else: x[:] = 0\n",
        "\n",
        "            # UNDERSAMPLE SIGNAL 200Hz to 60Hz (minimum sr for not loosing information on the 0-30Hz bandwith (shanon-nyquist))\n",
        "            x  = scipy.signal.resample(x, 512)\n",
        "\n",
        "            # RAW SPECTROGRAM\n",
        "            fs = 60\n",
        "            frequencies = np.linspace(0.2, 30, 128) / fs # normalize\n",
        "            scale = pywt.frequency2scale('cmor1-0.5', frequencies)\n",
        "            scalo , freqs = pywt.cwt(x, scale, 'cmor1-0.5', sampling_period = 1/fs)\n",
        "\n",
        "            # LOG TRANSFORM\n",
        "            width = (scalo.shape[1]//32)*32\n",
        "            scalo_db = librosa.power_to_db(np.abs(scalo), ref=1).astype(np.float32)[:,:width]\n",
        "\n",
        "            img[:,:,k] += scalo_db\n",
        "\n",
        "        # AVERAGE THE 4 MONTAGE DIFFERENCES\n",
        "        img[:,:,k] /= 4.0\n",
        "\n",
        "        # STANDARDIZE PER IMAGE\n",
        "        ep = 1e-6\n",
        "        m = np.nanmean(img.flatten())\n",
        "        s = np.nanstd(img.flatten())\n",
        "        img = (img-m)/(s+ep)\n",
        "        img = np.nan_to_num(img, nan=0.0)\n",
        "\n",
        "        if display:\n",
        "            plt.subplot(2,2,k+1)\n",
        "            plt.imshow(img[:,:,k],aspect='auto',origin='lower')\n",
        "            plt.title(f'EEG {eeg_id} - Scalogram {NAMES[k]}')\n",
        "            plt.show()\n",
        "\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-02-07T20:27:11.655268Z",
          "iopub.status.busy": "2024-02-07T20:27:11.654346Z"
        },
        "id": "zNVudrRETesB",
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "import cv2 as cv\n",
        "\n",
        "scalos = {}\n",
        "for index, row in train.iterrows():\n",
        "        r = int( (row['min_eeg'] + row['max_eeg'])//4 )\n",
        "        parquet_path = row['path_eeg']\n",
        "        eeg_id = row['eeg_id']\n",
        "        print(index, row['target'])\n",
        "        img = scalogram_from_eeg(parquet_path, r, eeg_id, display=False)\n",
        "        resized = np.zeros((128,256,4))\n",
        "        for i in range(4):\n",
        "            resized[:,:,i] = cv.resize(img[:,:,i], (256,128))\n",
        "        scalos[eeg_id] = resized\n",
        "\n",
        "\n",
        "\n",
        "np.save(\"scalos.npy\", scalos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5O5MIDBCcKs"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "from googleapiclient.http import MediaFileUpload\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "auth.authenticate_user()\n",
        "\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "def save_file_to_drive(name, path):\n",
        "    file_metadata = {\n",
        "      'name': name,\n",
        "      'mimeType': 'application/octet-stream'\n",
        "     }\n",
        "\n",
        "    media = MediaFileUpload(path,\n",
        "                    mimetype='application/octet-stream',\n",
        "                    resumable=True)\n",
        "\n",
        "    created = drive_service.files().create(body=file_metadata,\n",
        "                                   media_body=media,\n",
        "                                   fields='id').execute()\n",
        "\n",
        "    print('File ID: {}'.format(created.get('id')))\n",
        "\n",
        "    return created\n",
        "\n",
        "save_file_to_drive(\"scalos.npy\",\"scalos.npy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ejU-uowXcCr"
      },
      "source": [
        "## Read scalograms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSLSqf8YTesC"
      },
      "outputs": [],
      "source": [
        "READ_SCALO_FILE = True\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "if READ_SCALO_FILE:\n",
        "    with open('/content/drive/MyDrive/scalos.npy', 'rb') as f:\n",
        "        scalograms = np.load(f,allow_pickle=True).item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2axV4pIan3NV"
      },
      "source": [
        "# Spectrograms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3u8Qj_9aXZSZ"
      },
      "source": [
        "## Create Spectrograms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwPK85A6X8qX"
      },
      "outputs": [],
      "source": [
        "def spectrogram_from_eeg(parquet_path):\n",
        "\n",
        "    # LOAD MIDDLE 50 SECONDS OF EEG SERIES\n",
        "    eeg = pd.read_parquet(parquet_path)\n",
        "    middle = (len(eeg)-10_000)//2\n",
        "    eeg = eeg.iloc[middle:middle+10_000]\n",
        "\n",
        "    # VARIABLE TO HOLD SPECTROGRAM\n",
        "    img = np.zeros((128,256,4),dtype='float32')\n",
        "\n",
        "    signals = []\n",
        "    for k in range(4):\n",
        "        COLS = FEATS[k]\n",
        "\n",
        "        for kk in range(4):\n",
        "\n",
        "            # COMPUTE PAIR DIFFERENCES\n",
        "            x = eeg[COLS[kk]].values - eeg[COLS[kk+1]].values\n",
        "\n",
        "            # FILL NANS\n",
        "            m = np.nanmean(x)\n",
        "            if np.isnan(x).mean()<1: x = np.nan_to_num(x,nan=m)\n",
        "            else: x[:] = 0\n",
        "\n",
        "            signals.append(x)\n",
        "\n",
        "            # RAW SPECTROGRAM\n",
        "            mel_spec = librosa.feature.melspectrogram(y=x, sr=200, hop_length=len(x)//256,\n",
        "                  n_fft=1024, n_mels=128, fmin=0, fmax=20, win_length=128)\n",
        "\n",
        "            # LOG TRANSFORM\n",
        "            width = (mel_spec.shape[1]//32)*32\n",
        "            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max).astype(np.float32)[:,:width]\n",
        "\n",
        "            # STANDARDIZE TO -1 TO 1\n",
        "            mel_spec_db = (mel_spec_db+40)/40\n",
        "            img[:,:,k] += mel_spec_db\n",
        "\n",
        "        # AVERAGE THE 4 MONTAGE DIFFERENCES\n",
        "        img[:,:,k] /= 4.0\n",
        "\n",
        "\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qco_7ZZYCMJ"
      },
      "outputs": [],
      "source": [
        "spectrograms = {}\n",
        "for index, row in train.iterrows():\n",
        "        r = int( (row['min_eeg'] + row['max_eeg'])//4 )\n",
        "        parquet_path = row['path_eeg']\n",
        "        eeg_id = row['eeg_id']\n",
        "        print(index, row['target'])\n",
        "        img = spectrogram_from_eeg(parquet_path, r, eeg_id, display=False)\n",
        "        resized = np.zeros((128,256,4))\n",
        "        for i in range(4):\n",
        "            resized[:,:,i] = cv.resize(img[:,:,i], (256,128))\n",
        "        spectrograms[eeg_id] = resized\n",
        "\n",
        "\n",
        "\n",
        "np.save(\"spectrograms.npy\", spectrograms)\n",
        "save_file_to_drive(\"spectrograms.npy\",\"spectrograms.npy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSDm3_wYTesC"
      },
      "source": [
        "## Read Train Spectrograms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2024-02-03T02:39:50.021768Z",
          "iopub.status.busy": "2024-02-03T02:39:50.021444Z",
          "iopub.status.idle": "2024-02-03T02:41:55.37038Z",
          "shell.execute_reply": "2024-02-03T02:41:55.369257Z",
          "shell.execute_reply.started": "2024-02-03T02:39:50.021734Z"
        },
        "id": "BBczQONNTesC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "READ_KAGGLE_SPECS = False\n",
        "\n",
        "# READ KAGGLE SPECTROGRAMS\n",
        "PATH = '/kaggle/input/hms-harmful-brain-activity-classification/train_spectrograms/'\n",
        "files = os.listdir(PATH)\n",
        "print(f'There are {len(files)} spectrogram parquets')\n",
        "\n",
        "if READ_KAGGLE_SPECS:\n",
        "    spectrograms = {}\n",
        "    for i,f in enumerate(files):\n",
        "        if i%100==0: print(i,', ',end='')\n",
        "        tmp = pd.read_parquet(f'{PATH}{f}')\n",
        "        name = int(f.split('.')[0])\n",
        "        spectrograms[name] = tmp.iloc[:,1:].values\n",
        "else:\n",
        "    with open('/content/drive/MyDrive/spectrograms.npy', 'rb') as f:\n",
        "          spectrograms = np.load(f,allow_pickle=True).item()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJqG9dq5TesC"
      },
      "source": [
        "# DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54-6q2zPnQEo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3):\n",
        "    def eraser(input_img):\n",
        "        if input_img.ndim == 3:\n",
        "            img_h, img_w, img_c = input_img.shape\n",
        "        elif input_img.ndim == 2:\n",
        "            img_h, img_w = input_img.shape\n",
        "\n",
        "        p_1 = np.random.rand()\n",
        "\n",
        "        if p_1 > p:\n",
        "            return input_img\n",
        "\n",
        "        while True:\n",
        "            s = np.random.uniform(s_l, s_h) * img_h * img_w\n",
        "            r = np.random.uniform(r_1, r_2)\n",
        "            w = int(np.sqrt(s / r))\n",
        "            h = int(np.sqrt(s * r))\n",
        "            left = np.random.randint(0, img_w)\n",
        "            top = np.random.randint(0, img_h)\n",
        "\n",
        "            if left + w <= img_w and top + h <= img_h:\n",
        "                break\n",
        "\n",
        "        if input_img.ndim == 3:\n",
        "            c = np.zeros((h, w, img_c))\n",
        "        if input_img.ndim == 2:\n",
        "            c = np.zeros((h, w))\n",
        "\n",
        "        input_img[top:top + h, left:left + w] = c\n",
        "\n",
        "        return input_img\n",
        "\n",
        "    return eraser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2024-02-03T02:41:55.373472Z",
          "iopub.status.busy": "2024-02-03T02:41:55.373138Z",
          "iopub.status.idle": "2024-02-03T02:41:57.344119Z",
          "shell.execute_reply": "2024-02-03T02:41:57.342928Z",
          "shell.execute_reply.started": "2024-02-03T02:41:55.373445Z"
        },
        "id": "0AfAAlZKTesC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "TARS = {'Seizure':0, 'LPD':1, 'GPD':2, 'LRDA':3, 'GRDA':4, 'Other':5}\n",
        "TARS2 = {x:y for y,x in TARS.items()}\n",
        "\n",
        "class DataGenerator(tf.keras.utils.Sequence):\n",
        "    'Generates data for Keras'\n",
        "    def __init__(self, data, batch_size=32, shuffle=False, augment=False, mode='train',\n",
        "                 specs = spectrograms, scalos = scalograms):\n",
        "\n",
        "        self.data = data\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.augment = augment\n",
        "        self.mode = mode\n",
        "        self.specs = specs\n",
        "        self.scalos = scalograms\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        ct = int( np.ceil( len(self.data) / self.batch_size ) )\n",
        "        return ct\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        X, y = self.__data_generation(indexes)\n",
        "        if self.augment: X = self.__augment_batch(X)\n",
        "        if self.mode!='test':\n",
        "          return X, y\n",
        "        else:\n",
        "          return X\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange( len(self.data) )\n",
        "        if self.shuffle: np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, indexes):\n",
        "        'Generates data containing batch_size samples'\n",
        "\n",
        "        X = np.zeros((len(indexes),128,256,8),dtype='float32')\n",
        "        y = np.zeros((len(indexes),6),dtype='float32')\n",
        "        if self.mode=='test':\n",
        "          self.y = y\n",
        "        img = np.ones((128,256),dtype='float32')\n",
        "\n",
        "        for j,i in enumerate(indexes):\n",
        "            row = self.data.iloc[i]\n",
        "            if self.mode=='test':\n",
        "                r = int( (row['min'] + row['max'])//4 )\n",
        "            else:\n",
        "                r = int( (row['min'] + row['max'])//4 )\n",
        "            if READ_KAGGLE_SPECS:\n",
        "              for k in range(4):\n",
        "                  # EXTRACT 300 ROWS OF SPECTROGRAM\n",
        "                  img = self.specs[row.spec_id][r:r+300,k*100:(k+1)*100].T\n",
        "\n",
        "                  # LOG TRANSFORM SPECTROGRAM\n",
        "                  img = np.clip(img,np.exp(-4),np.exp(8))\n",
        "                  img = np.log(img)\n",
        "\n",
        "                  # STANDARDIZE PER IMAGE\n",
        "                  ep = 1e-6\n",
        "                  m = np.nanmean(img.flatten())\n",
        "                  s = np.nanstd(img.flatten())\n",
        "                  img = (img-m)/(s+ep)\n",
        "                  img = np.nan_to_num(img, nan=0.0)\n",
        "\n",
        "                  # CROP TO 256 TIME STEPS\n",
        "                  X[j,14:-14,:,k] = img[:,22:-22] / 2.0\n",
        "\n",
        "            else:\n",
        "              img = self.specs[row.eeg_id]\n",
        "              X[j,:,:,:4] = img\n",
        "\n",
        "            # EEG SCALOGRAMS\n",
        "            img = self.scalos[row.eeg_id]\n",
        "            X[j,:,:,4:] = img\n",
        "\n",
        "            if self.mode!='test':\n",
        "                y[j,] = row[TARGETS]\n",
        "            if self.mode == 'test':\n",
        "                self.y[j,] = row[TARGETS]\n",
        "\n",
        "            x1 = [X[:,:,:,i:i+1] for i in range(4)]\n",
        "            x1 = tf.keras.layers.Concatenate(axis=1)(x1)\n",
        "            # EEG SPECTROGRAMS\n",
        "            x2 = [X[:,:,:,i+4:i+5] for i in range(4)]\n",
        "            x2 = tf.keras.layers.Concatenate(axis=1)(x2)\n",
        "            # MAKE 512X512X3\n",
        "            x = tf.keras.layers.Concatenate(axis=2)([x1,x2])\n",
        "            x = tf.keras.layers.Concatenate(axis=3)([x])\n",
        "\n",
        "        return x,y\n",
        "\n",
        "    def __augment_batch(self, img_batch):\n",
        "        eraser = get_random_eraser()\n",
        "        img_batch = img_batch.numpy()\n",
        "        for i in range(img_batch.shape[0]):\n",
        "\n",
        "            img_batch[i, ] = eraser(img_batch[i, ])\n",
        "        return tf.convert_to_tensor(img_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b7b-WWutTesC"
      },
      "source": [
        "# Effnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ur_eXSfvt5Kz"
      },
      "outputs": [],
      "source": [
        "! pip install tf-models-official"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-03T02:42:12.997375Z",
          "iopub.status.busy": "2024-02-03T02:42:12.997012Z",
          "iopub.status.idle": "2024-02-03T02:42:13.038746Z",
          "shell.execute_reply": "2024-02-03T02:42:13.037816Z",
          "shell.execute_reply.started": "2024-02-03T02:42:12.997344Z"
        },
        "id": "d3e3bApwTesC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "def build_model(pretrain=None):\n",
        "\n",
        "    inp = tf.keras.Input(shape=(512,512,1))\n",
        "    base_model =  tf.keras.applications.efficientnet.EfficientNetB0(weights=None,\n",
        "                                                                input_shape=None,\n",
        "                                                                classes=6,\n",
        "                                                                classifier_activation='softmax')\n",
        "\n",
        "\n",
        "    if pretrain:\n",
        "        base_model.load_weights(pretrain)\n",
        "\n",
        "\n",
        "    # OUTPUT\n",
        "    x = base_model(inp)\n",
        "    # x = tf.keras.layers.GlobalAveragePooling2D()(x0)\n",
        "    # x = tf.keras.layers.Dense(6,activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    # COMPILE MODEL\n",
        "    model = tf.keras.Model(inputs=inp, outputs=x)\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate = 1e-3)\n",
        "    loss = tf.keras.losses.KLDivergence()\n",
        "\n",
        "    model.compile(loss=loss, optimizer = opt)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsOj-Rte0OWV"
      },
      "source": [
        "# MixNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhMRttRpB_yR"
      },
      "source": [
        "Implementation based on: [Mixed Link Networks](https://arxiv.org/pdf/1802.01808.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuL49xzs0MiO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "INPUT_SHAPE = (512,512,1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Conv2D_Input(x, filters):\n",
        "    x = layers.Conv2D(filters,\n",
        "                (7,7),\n",
        "                strides=2,\n",
        "                input_shape=INPUT_SHAPE, kernel_initializer=tf.keras.initializers.HeNormal())(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(3, 3),\n",
        "                            strides=2)(x)\n",
        "    return x\n",
        "\n",
        "def Conv2D_transition(x, k):\n",
        "    x = layers.Conv2D(k,\n",
        "                (1,1),\n",
        "                padding='same', kernel_initializer=tf.keras.initializers.HeNormal())(x)\n",
        "    x = layers.AveragePooling2D(pool_size=(2, 2),\n",
        "                            strides=2,\n",
        "                            padding='valid')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def MLBlock(x,k1,k2):\n",
        "    input_ = x\n",
        "\n",
        "    x_add = layers.BatchNormalization()(x)\n",
        "    x_add = layers.ReLU()(x_add)\n",
        "    x_add = layers.Conv2D(k1,\n",
        "                (1, 1),\n",
        "                padding='same', kernel_initializer=tf.keras.initializers.HeNormal())(x_add)\n",
        "    x_add = layers.BatchNormalization()(x_add)\n",
        "    x_add = layers.ReLU()(x_add)\n",
        "    x_add = layers.Conv2D(k1,\n",
        "                (3, 3),\n",
        "                padding='same', kernel_initializer=tf.keras.initializers.HeNormal())(x_add)\n",
        "\n",
        "\n",
        "    x_concat = layers.BatchNormalization()(x)\n",
        "    x_concat = layers.ReLU()(x_concat)\n",
        "    x_concat = layers.Conv2D(k2,\n",
        "                (1, 1),\n",
        "                padding='same', kernel_initializer=tf.keras.initializers.HeNormal())(x_concat)\n",
        "    x_concat = layers.BatchNormalization()(x_concat)\n",
        "    x_concat = layers.ReLU()(x_concat)\n",
        "    x_concat = layers.Conv2D(k2,\n",
        "                (3, 3),\n",
        "                padding='same', kernel_initializer=tf.keras.initializers.HeNormal())(x_concat)\n",
        "    x_add = layers.Add()([x[:,:,:,-k1:], x_add])\n",
        "    x = layers.Concatenate(axis=3)([x[:,:,:,:-k1], x_add])\n",
        "\n",
        "    x = layers.Concatenate(axis=3)([x, x_concat])\n",
        "    return x\n",
        "\n",
        "def build_MixNet_model(k,MLB1,MLB2,MLB3,MLB4):\n",
        "    global strategy\n",
        "    with strategy.scope():\n",
        "        # inputs\n",
        "        inputs = layers.Input(shape=INPUT_SHAPE)\n",
        "\n",
        "        x_0 = layers.BatchNormalization()(inputs)\n",
        "        x_1 = Conv2D_Input(x_0, 2*k)\n",
        "\n",
        "        for i in range(MLB1):\n",
        "            x_1 = MLBlock(x_1,k,k)\n",
        "            x_1 = MLBlock(x_1,k,k)\n",
        "\n",
        "#         x_1 = layers.Dropout(0.2)(x_1)\n",
        "        x_2 = Conv2D_transition(x_1, k)\n",
        "\n",
        "        for i in range(MLB2):\n",
        "            x_2 = MLBlock(x_2,k,k)\n",
        "            x_2 = MLBlock(x_2,k,k)\n",
        "\n",
        "#         x_2 = layers.Dropout(0.2)(x_2)\n",
        "        x_3 = Conv2D_transition(x_2, k)\n",
        "\n",
        "        for i in range(MLB3):\n",
        "            x_3 = MLBlock(x_3,k,k)\n",
        "            x_3 = MLBlock(x_3,k,k)\n",
        "#         x_3 = layers.Dropout(0.2)(x_3)\n",
        "        x_4 = Conv2D_transition(x_3, k)\n",
        "\n",
        "        for i in range(MLB4):\n",
        "            x_4 = MLBlock(x_4,k,k)\n",
        "            x_4 = MLBlock(x_4,k,k)\n",
        "\n",
        "        x_4 = layers.BatchNormalization()(x_1)\n",
        "        x_4 = layers.ReLU()(x_4)\n",
        "        x_pooled = layers.GlobalAveragePooling2D(data_format='channels_last')(x_4)\n",
        "\n",
        "        outputs = layers.Dense(6, activation='softmax', kernel_initializer=tf.keras.initializers.HeNormal())(x_pooled)\n",
        "\n",
        "        model = tf.keras.Model(inputs, outputs, name=\"ML-Net\")\n",
        "        opt = tf.keras.optimizers.Adam()\n",
        "        loss = tf.keras.losses.KLDivergence()\n",
        "\n",
        "        model.compile(loss=loss, optimizer = opt)\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bsIr6Tdq1qx"
      },
      "source": [
        "# AdaBoost_CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rv3pXOQGBiE3"
      },
      "source": [
        "Implementation based on:\n",
        "\n",
        "[AdaBoost-CNN: An adaptive boosting algorithm for convolutional neural networks to\n",
        "classify multi-class imbalanced datasets using transfer learning](https://pure.ulster.ac.uk/ws/portalfiles/portal/78735598/AdaBoost_CNN_Aboozar.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlWGCJ6VsAky"
      },
      "source": [
        "## Weak CNN classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-kFNWkfu4y2"
      },
      "source": [
        "### AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEln43tHsAKr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "INPUT_SHAPE = (512,512,1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def Conv2D(x, filters, kernel_size, stride, dropout_rate, maxpool = False):\n",
        "    x = layers.Conv2D(filters,\n",
        "                kernel_size,\n",
        "                strides=stride,\n",
        "                kernel_initializer=tf.keras.initializers.HeNormal(),\n",
        "                padding = 'same')(x)\n",
        "    if maxpool:\n",
        "      x = layers.MaxPooling2D(pool_size=4)(x)\n",
        "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def AlexNet_weak_classifier():\n",
        "\n",
        "    inputs = layers.Input(shape=INPUT_SHAPE)\n",
        "    x_norm = layers.BatchNormalization()(inputs)\n",
        "    x = Conv2D(x_norm, 48, 11, 8, 0.5, maxpool = True)\n",
        "    x = Conv2D(x, 128, 5, 1, 0.5, maxpool = True)\n",
        "    x = Conv2D(x, 256, 3, 1, 0.5)\n",
        "    x = Conv2D(x, 256, 3, 1, 0.5)\n",
        "    x = Conv2D(x, 200, 3, 1, 0.5, maxpool = True)\n",
        "    x = layers.GlobalAveragePooling2D(data_format='channels_last')(x)\n",
        "    x = layers.Dense(1028, activation='relu')(x)\n",
        "    x = layers.Dense(1028, activation='relu')(x)\n",
        "    outputs = layers.Dense(6, activation='softmax')(x)\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bfpn9Zvu0I3n"
      },
      "source": [
        "## AdaBoost CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m17AaOIo0QqR"
      },
      "outputs": [],
      "source": [
        "from keras import backend as K\n",
        "\n",
        "class AdaBoost_CNN():\n",
        "    def __init__(self, weak_classifier, nbr_classifiers, nbr_data_samples):\n",
        "      self.D = np.ones(nbr_data_samples, dtype=np.float32)/nbr_data_samples\n",
        "      self.weak_classifier = weak_classifier\n",
        "      with strategy.scope():\n",
        "        self.weak_classifiers = [weak_classifier() for i in range(nbr_classifiers)]\n",
        "\n",
        "    def get_model(self, i):\n",
        "      global strategy\n",
        "      model = self.weak_classifiers[i]\n",
        "      if i != 0:\n",
        "        prev_model = self.weak_classifiers[i-1]\n",
        "        weights = prev_model.get_weights()\n",
        "        model.set_weights(weights)\n",
        "      return model\n",
        "\n",
        "    def update_D(self, learning_rate, y_true, y_pred):\n",
        "      # Displace zero probabilities so the log is defined.\n",
        "      # Also fix negative elements which may occur with\n",
        "      # negative sample weights.\n",
        "      y_pred[y_pred < np.finfo(y_pred.dtype).eps] = np.finfo(y_pred.dtype).eps\n",
        "\n",
        "      for i in range(self.D.shape[0]):\n",
        "        self.D[i] *= tf.math.exp(-learning_rate*(5./6)*tf.tensordot(y_true[i,:], tf.math.log(y_pred[i,:])))\n",
        "      sum = tf.math.reduce_sum(self.D)\n",
        "      self.D = self.D/sum\n",
        "\n",
        "    def train(self, train_dataset, validation_dataset, epochs, learning_rate, batch_size):\n",
        "      for i in range(len(self.weak_classifiers)):\n",
        "        # Model\n",
        "        model = self.get_model(i)\n",
        "\n",
        "        # Loss function\n",
        "        loss_fn = tf.keras.losses.KLDivergence()\n",
        "\n",
        "        # Optimizer with learning rate parameter\n",
        "        optimizer = tf.keras.optimizers.legacy.Adagrad()\n",
        "\n",
        "        # Metrics for training and validation\n",
        "        train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "        validation_loss = tf.keras.metrics.Mean(name='validation_loss')\n",
        "        if i == 0:\n",
        "          for epoch in range(epochs):\n",
        "            # Training loop\n",
        "            y_pred = []\n",
        "            y_true = []\n",
        "            K.set_value(optimizer.lr, learning_rate[epoch])\n",
        "            for batch, images, labels in enumerate(train_dataset):\n",
        "                with tf.GradientTape() as tape:\n",
        "                    predictions = model(images, training=True)\n",
        "                    loss = loss_fn(labels, predictions, sample_weight=self.D[batch*batch_size:min((batch+1)*batch_size,self.D.shape[0])])\n",
        "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "                    train_loss(loss)\n",
        "                y_true.extend(labels)\n",
        "                y_pred.extend(predictions)\n",
        "\n",
        "            # Validation loop\n",
        "            for val_images, val_labels in validation_dataset:\n",
        "                val_predictions = model(val_images, training=False)\n",
        "                v_loss = loss_fn(val_labels, val_predictions)\n",
        "                validation_loss(v_loss)\n",
        "\n",
        "            print(f\"Model {i + 1}, \"\n",
        "                  f\"Epoch {epoch + 1}, \"\n",
        "                  f\"Loss: {train_loss.result()}, \"\n",
        "                  f\"Validation Loss: {validation_loss.result()}, \")\n",
        "\n",
        "            # Reset metrics for the next epoch\n",
        "            train_loss.reset_states()\n",
        "            validation_loss.reset_states()\n",
        "\n",
        "            self.update_D(learning_rate[epoch], np.array(y_true), np.array(y_pred))\n",
        "\n",
        "        else:\n",
        "            # Training loop\n",
        "            y_pred = []\n",
        "            y_true = []\n",
        "            K.set_value(optimizer.lr, learning_rate[-1])\n",
        "            for batch, images, labels in enumerate(train_dataset):\n",
        "                with tf.GradientTape() as tape:\n",
        "                    predictions = model(images, training=True)\n",
        "                    loss = loss_fn(labels, predictions, sample_weight=self.D[batch*batch_size:min((batch+1)*batch_size,self.D.shape[0])])\n",
        "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "                    train_loss(loss)\n",
        "                y_true.extend(labels)\n",
        "                y_pred.extend(predictions)\n",
        "\n",
        "            # Validation loop\n",
        "            for val_images, val_labels in validation_dataset:\n",
        "                val_predictions = model(val_images, training=False)\n",
        "                v_loss = loss_fn(val_labels, val_predictions)\n",
        "                validation_loss(v_loss)\n",
        "\n",
        "            print(f\"Model {i + 1}, \"\n",
        "                  f\"Loss: {train_loss.result()}, \"\n",
        "                  f\"Validation Loss: {validation_loss.result()}, \")\n",
        "\n",
        "            # Reset metrics for the next epoch\n",
        "            train_loss.reset_states()\n",
        "            validation_loss.reset_states()\n",
        "\n",
        "            self.update_D(learning_rate[-1], np.array(y_true), np.array(y_pred))\n",
        "\n",
        "\n",
        "    def samme_proba(self, weak_classifier, X):\n",
        "        proba = weak_classifier.predict(X)\n",
        "\n",
        "        # Displace zero probabilities so the log is defined.\n",
        "        # Also fix negative elements which may occur with\n",
        "        # negative sample weights.\n",
        "        proba[proba < np.finfo(proba.dtype).eps] = np.finfo(proba.dtype).eps\n",
        "        log_proba = np.log(proba)\n",
        "\n",
        "        return 5 * (log_proba - (1./6)* log_proba.sum(axis=1)[:, np.newaxis])\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        proba = sum(self.samme_proba(weak_classifier, X)\n",
        "                    for weak_classifier in self.weak_classifiers)\n",
        "\n",
        "        proba /= len(self.weak_classifiers)\n",
        "        proba = np.exp((1./5) * proba)\n",
        "        normalizer = proba.sum(axis=1)[:, np.newaxis]\n",
        "        normalizer[normalizer == 0.0] = 1.0\n",
        "        proba /= normalizer\n",
        "\n",
        "        return proba\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iL90GCfa5XDF"
      },
      "source": [
        "## Training AdaBoost CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TOzaGSL65WFp",
        "outputId": "39c64d4d-9f4f-4de4-fc61-568b3ecd4a44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#########################\n",
            "### Fold 1\n",
            "### train size 13671, valid size 3418\n",
            "#########################\n"
          ]
        },
        {
          "ename": "InvalidArgumentError",
          "evalue": "Graph execution error:\n\nDetected at node custom_KL_div/kl_divergence/weighted_loss/Mul defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-43-143c95952d25>\", line 46, in <cell line: 32>\n\n  File \"<ipython-input-42-9d52993fa93e>\", line 61, in train\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call\n\n  File \"<ipython-input-42-9d52993fa93e>\", line 29, in custom_KL_div\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 161, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/losses_utils.py\", line 351, in compute_weighted_loss\n\nrequired broadcastable shapes\n\t [[{{node custom_KL_div/kl_divergence/weighted_loss/Mul}}]] [Op:__inference_train_function_26649]",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-143c95952d25>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdaBoost_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAlexNet_weak_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_gen_prediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-9d52993fa93e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, val_dataset, pred_dataset, epochs, learning_rate)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             model.fit(train_dataset, verbose=1,\n\u001b[0m\u001b[1;32m     62\u001b[0m                       \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                       epochs=1)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node custom_KL_div/kl_divergence/weighted_loss/Mul defined at (most recent call last):\n  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n\n  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n\n  File \"/usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n\n  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n\n  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n\n  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n\n  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n\n  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n\n  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n\n  File \"<ipython-input-43-143c95952d25>\", line 46, in <cell line: 32>\n\n  File \"<ipython-input-42-9d52993fa93e>\", line 61, in train\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1807, in fit\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1384, in step_function\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1373, in run_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1151, in train_step\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1209, in compute_loss\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/compile_utils.py\", line 277, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 143, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 270, in call\n\n  File \"<ipython-input-42-9d52993fa93e>\", line 29, in custom_KL_div\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/losses.py\", line 161, in __call__\n\n  File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/losses_utils.py\", line 351, in compute_weighted_loss\n\nrequired broadcastable shapes\n\t [[{{node custom_KL_div/kl_divergence/weighted_loss/Mul}}]] [Op:__inference_train_function_26649]"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold, GroupKFold\n",
        "import tensorflow.keras.backend as K\n",
        "import gc\n",
        "import math\n",
        "LR_START = 1e-6\n",
        "LR_MAX = 1e-3\n",
        "LR_MIN = 1e-6\n",
        "LR_RAMPUP_EPOCHS = 0\n",
        "LR_SUSTAIN_EPOCHS = 0\n",
        "EPOCHS = 10\n",
        "\n",
        "def lrfn(epoch):\n",
        "    if epoch < LR_RAMPUP_EPOCHS:\n",
        "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "        lr = LR_MAX\n",
        "    else:\n",
        "        decay_total_epochs = EPOCHS - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS - 1\n",
        "        decay_epoch_index = epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS\n",
        "        phase = math.pi * decay_epoch_index / decay_total_epochs\n",
        "        cosine_decay = 0.5 * (1 + math.cos(phase))\n",
        "        lr = (LR_MAX - LR_MIN) * cosine_decay + LR_MIN\n",
        "    return lr\n",
        "\n",
        "LR = [lrfn(x) for x in range(EPOCHS)]\n",
        "\n",
        "\n",
        "all_oof = []\n",
        "all_true = []\n",
        "\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "for i, (train_index, valid_index) in enumerate(gkf.split(train, train.target, train.patient_id)):\n",
        "\n",
        "    print('#'*25)\n",
        "    print(f'### Fold {i+1}')\n",
        "\n",
        "    train_gen = DataGenerator(train.iloc[train_index], shuffle=True, batch_size=16, augment=False)\n",
        "    valid_gen = DataGenerator(train.iloc[valid_index], shuffle=False, batch_size=32, mode='valid')\n",
        "\n",
        "    print(f'### train size {len(train_index)}, valid size {len(valid_index)}')\n",
        "    print('#'*25)\n",
        "\n",
        "    K.clear_session()\n",
        "    model = AdaBoost_CNN(AlexNet_weak_classifier, 6, len(train_index))\n",
        "    model.train(train_gen, valid_gen, EPOCHS, LR, 16)\n",
        "\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtLtV6_5Yiur"
      },
      "source": [
        "# Training EffNet or Mixet with cross validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "ePgf_eu-ZmR1",
        "outputId": "0f78d8f1-9536-4ca6-86c0-4d73cc6c86cd"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import math\n",
        "LR_START = 1e-6\n",
        "LR_MAX = 1e-3\n",
        "LR_MIN = 1e-6\n",
        "LR_RAMPUP_EPOCHS = 0\n",
        "LR_SUSTAIN_EPOCHS = 0\n",
        "EPOCHS = 10\n",
        "\n",
        "def lrfn(epoch):\n",
        "    if epoch < LR_RAMPUP_EPOCHS:\n",
        "        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n",
        "    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n",
        "        lr = LR_MAX\n",
        "    else:\n",
        "        decay_total_epochs = EPOCHS - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS - 1\n",
        "        decay_epoch_index = epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS\n",
        "        phase = math.pi * decay_epoch_index / decay_total_epochs\n",
        "        cosine_decay = 0.5 * (1 + math.cos(phase))\n",
        "        lr = (LR_MAX - LR_MIN) * cosine_decay + LR_MIN\n",
        "    return lr\n",
        "\n",
        "rng = [i for i in range(EPOCHS)]\n",
        "lr_y = [lrfn(x) for x in rng]\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(rng, lr_y, '-o')\n",
        "plt.xlabel('epoch',size=14); plt.ylabel('learning rate',size=14)\n",
        "plt.title('Cosine Training Schedule',size=16); plt.show()\n",
        "\n",
        "LR = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4fFyvQ9ZYVzG",
        "outputId": "20dd5350-168b-4de9-8d89-bfd56aae91da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#########################\n",
            "### Fold 1\n",
            "### train size 13671, valid size 3418\n",
            "#########################\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1/10\n",
            "855/855 [==============================] - 517s 570ms/step - loss: 1.1535 - val_loss: 2.0034 - lr: 0.0010\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0009698764640825614.\n",
            "Epoch 2/10\n",
            "855/855 [==============================] - 470s 550ms/step - loss: 0.8725 - val_loss: 1.1934 - lr: 9.6988e-04\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0008831391993379295.\n",
            "Epoch 3/10\n",
            "855/855 [==============================] - 483s 565ms/step - loss: 0.7702 - val_loss: 1.0895 - lr: 8.8314e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0007502500000000002.\n",
            "Epoch 4/10\n",
            "855/855 [==============================] - 494s 578ms/step - loss: 0.7085 - val_loss: 1.1831 - lr: 7.5025e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0005872372647446319.\n",
            "Epoch 5/10\n",
            "855/855 [==============================] - 489s 572ms/step - loss: 0.6509 - val_loss: 0.8024 - lr: 5.8724e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0004137627352553684.\n",
            "Epoch 6/10\n",
            "855/855 [==============================] - 491s 574ms/step - loss: 0.5898 - val_loss: 0.7772 - lr: 4.1376e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.00025075000000000016.\n",
            "Epoch 7/10\n",
            "855/855 [==============================] - 504s 590ms/step - loss: 0.5049 - val_loss: 0.8526 - lr: 2.5075e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.00011786080066207055.\n",
            "Epoch 8/10\n",
            "855/855 [==============================] - 473s 554ms/step - loss: 0.4023 - val_loss: 0.8276 - lr: 1.1786e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 3.11235359174388e-05.\n",
            "Epoch 9/10\n",
            "855/855 [==============================] - 488s 571ms/step - loss: 0.3246 - val_loss: 0.8518 - lr: 3.1124e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 10/10\n",
            "855/855 [==============================] - 495s 579ms/step - loss: 0.3040 - val_loss: 0.8629 - lr: 1.0000e-06\n",
            "107/107 [==============================] - 129s 1s/step\n",
            "#########################\n",
            "### Fold 2\n",
            "### train size 13671, valid size 3418\n",
            "#########################\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1/10\n",
            "855/855 [==============================] - 538s 593ms/step - loss: 1.1817 - val_loss: 1.0827 - lr: 0.0010\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0009698764640825614.\n",
            "Epoch 2/10\n",
            "855/855 [==============================] - 504s 590ms/step - loss: 0.8201 - val_loss: 0.9393 - lr: 9.6988e-04\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0008831391993379295.\n",
            "Epoch 3/10\n",
            "855/855 [==============================] - 497s 581ms/step - loss: 0.7260 - val_loss: 0.8772 - lr: 8.8314e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0007502500000000002.\n",
            "Epoch 4/10\n",
            "855/855 [==============================] - 503s 588ms/step - loss: 0.6682 - val_loss: 0.7251 - lr: 7.5025e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0005872372647446319.\n",
            "Epoch 5/10\n",
            "855/855 [==============================] - 500s 585ms/step - loss: 0.6098 - val_loss: 0.7781 - lr: 5.8724e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0004137627352553684.\n",
            "Epoch 6/10\n",
            "855/855 [==============================] - 492s 576ms/step - loss: 0.5520 - val_loss: 0.7242 - lr: 4.1376e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.00025075000000000016.\n",
            "Epoch 7/10\n",
            "855/855 [==============================] - 518s 606ms/step - loss: 0.4754 - val_loss: 0.7516 - lr: 2.5075e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.00011786080066207055.\n",
            "Epoch 8/10\n",
            "855/855 [==============================] - 519s 607ms/step - loss: 0.3826 - val_loss: 0.8140 - lr: 1.1786e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 3.11235359174388e-05.\n",
            "Epoch 9/10\n",
            "855/855 [==============================] - 493s 577ms/step - loss: 0.3097 - val_loss: 0.7999 - lr: 3.1124e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 10/10\n",
            "855/855 [==============================] - 487s 570ms/step - loss: 0.2854 - val_loss: 0.8143 - lr: 1.0000e-06\n",
            "107/107 [==============================] - 114s 1s/step\n",
            "#########################\n",
            "### Fold 3\n",
            "### train size 13671, valid size 3418\n",
            "#########################\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1/10\n",
            "855/855 [==============================] - 522s 575ms/step - loss: 1.1931 - val_loss: 1.0495 - lr: 0.0010\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0009698764640825614.\n",
            "Epoch 2/10\n",
            "855/855 [==============================] - 494s 577ms/step - loss: 0.8487 - val_loss: 0.8802 - lr: 9.6988e-04\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0008831391993379295.\n",
            "Epoch 3/10\n",
            "855/855 [==============================] - 498s 583ms/step - loss: 0.7488 - val_loss: 0.7951 - lr: 8.8314e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0007502500000000002.\n",
            "Epoch 4/10\n",
            "855/855 [==============================] - 479s 560ms/step - loss: 0.6791 - val_loss: 0.9071 - lr: 7.5025e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0005872372647446319.\n",
            "Epoch 5/10\n",
            "855/855 [==============================] - 486s 569ms/step - loss: 0.6197 - val_loss: 0.7789 - lr: 5.8724e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0004137627352553684.\n",
            "Epoch 6/10\n",
            "855/855 [==============================] - 492s 576ms/step - loss: 0.5531 - val_loss: 0.7513 - lr: 4.1376e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.00025075000000000016.\n",
            "Epoch 7/10\n",
            "855/855 [==============================] - 498s 583ms/step - loss: 0.4564 - val_loss: 0.8241 - lr: 2.5075e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.00011786080066207055.\n",
            "Epoch 8/10\n",
            "855/855 [==============================] - 495s 578ms/step - loss: 0.3609 - val_loss: 0.7329 - lr: 1.1786e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 3.11235359174388e-05.\n",
            "Epoch 9/10\n",
            "855/855 [==============================] - 481s 563ms/step - loss: 0.2942 - val_loss: 0.7904 - lr: 3.1124e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 10/10\n",
            "855/855 [==============================] - 481s 563ms/step - loss: 0.2720 - val_loss: 0.7888 - lr: 1.0000e-06\n",
            "107/107 [==============================] - 109s 1s/step\n",
            "#########################\n",
            "### Fold 4\n",
            "### train size 13671, valid size 3418\n",
            "#########################\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1/10\n",
            "855/855 [==============================] - 511s 562ms/step - loss: 1.1692 - val_loss: 1.0926 - lr: 0.0010\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0009698764640825614.\n",
            "Epoch 2/10\n",
            "855/855 [==============================] - 489s 572ms/step - loss: 0.8535 - val_loss: 1.0816 - lr: 9.6988e-04\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0008831391993379295.\n",
            "Epoch 3/10\n",
            "855/855 [==============================] - 490s 574ms/step - loss: 0.7480 - val_loss: 0.9892 - lr: 8.8314e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0007502500000000002.\n",
            "Epoch 4/10\n",
            "855/855 [==============================] - 492s 575ms/step - loss: 0.6752 - val_loss: 0.9913 - lr: 7.5025e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0005872372647446319.\n",
            "Epoch 5/10\n",
            "855/855 [==============================] - 480s 561ms/step - loss: 0.6083 - val_loss: 0.7973 - lr: 5.8724e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0004137627352553684.\n",
            "Epoch 6/10\n",
            "855/855 [==============================] - 489s 572ms/step - loss: 0.5415 - val_loss: 0.7158 - lr: 4.1376e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.00025075000000000016.\n",
            "Epoch 7/10\n",
            "855/855 [==============================] - 474s 554ms/step - loss: 0.4637 - val_loss: 0.7597 - lr: 2.5075e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.00011786080066207055.\n",
            "Epoch 8/10\n",
            "855/855 [==============================] - 474s 555ms/step - loss: 0.3679 - val_loss: 0.7629 - lr: 1.1786e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 3.11235359174388e-05.\n",
            "Epoch 9/10\n",
            "855/855 [==============================] - 481s 563ms/step - loss: 0.3024 - val_loss: 0.7915 - lr: 3.1124e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 10/10\n",
            "855/855 [==============================] - 492s 576ms/step - loss: 0.2769 - val_loss: 0.8017 - lr: 1.0000e-06\n",
            "107/107 [==============================] - 119s 1s/step\n",
            "#########################\n",
            "### Fold 5\n",
            "### train size 13672, valid size 3417\n",
            "#########################\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
            "Epoch 1/10\n",
            "855/855 [==============================] - 504s 555ms/step - loss: 1.3532 - val_loss: 1.7431 - lr: 0.0010\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0009698764640825614.\n",
            "Epoch 2/10\n",
            "855/855 [==============================] - 502s 588ms/step - loss: 1.0157 - val_loss: 0.9025 - lr: 9.6988e-04\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0008831391993379295.\n",
            "Epoch 3/10\n",
            "855/855 [==============================] - 484s 566ms/step - loss: 0.8273 - val_loss: 0.9219 - lr: 8.8314e-04\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0007502500000000002.\n",
            "Epoch 4/10\n",
            "855/855 [==============================] - 482s 564ms/step - loss: 0.7328 - val_loss: 0.8324 - lr: 7.5025e-04\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0005872372647446319.\n",
            "Epoch 5/10\n",
            "855/855 [==============================] - 469s 549ms/step - loss: 0.6678 - val_loss: 0.6902 - lr: 5.8724e-04\n",
            "\n",
            "Epoch 6: LearningRateScheduler setting learning rate to 0.0004137627352553684.\n",
            "Epoch 6/10\n",
            "855/855 [==============================] - 479s 561ms/step - loss: 0.6056 - val_loss: 0.7194 - lr: 4.1376e-04\n",
            "\n",
            "Epoch 7: LearningRateScheduler setting learning rate to 0.00025075000000000016.\n",
            "Epoch 7/10\n",
            "855/855 [==============================] - 475s 556ms/step - loss: 0.5364 - val_loss: 0.6994 - lr: 2.5075e-04\n",
            "\n",
            "Epoch 8: LearningRateScheduler setting learning rate to 0.00011786080066207055.\n",
            "Epoch 8/10\n",
            "855/855 [==============================] - 499s 584ms/step - loss: 0.4623 - val_loss: 0.6626 - lr: 1.1786e-04\n",
            "\n",
            "Epoch 9: LearningRateScheduler setting learning rate to 3.11235359174388e-05.\n",
            "Epoch 9/10\n",
            "855/855 [==============================] - 482s 564ms/step - loss: 0.4019 - val_loss: 0.6691 - lr: 3.1124e-05\n",
            "\n",
            "Epoch 10: LearningRateScheduler setting learning rate to 1e-06.\n",
            "Epoch 10/10\n",
            "855/855 [==============================] - 463s 541ms/step - loss: 0.3797 - val_loss: 0.6720 - lr: 1.0000e-06\n",
            "107/107 [==============================] - 125s 1s/step\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import KFold, GroupKFold\n",
        "import tensorflow.keras.backend as K, gc\n",
        "\n",
        "LOAD_MODELS_FROM\n",
        "\n",
        "all_oof = []\n",
        "all_true = []\n",
        "\n",
        "gkf = GroupKFold(n_splits=5)\n",
        "for i, (train_index, valid_index) in enumerate(gkf.split(train, train.target, train.patient_id)):\n",
        "\n",
        "    print('#'*25)\n",
        "    print(f'### Fold {i+1}')\n",
        "\n",
        "    train_gen = DataGenerator(train.iloc[train_index], shuffle=True, batch_size=16, augment=False)\n",
        "    valid_gen = DataGenerator(train.iloc[valid_index], shuffle=False, batch_size=32, mode='valid')\n",
        "\n",
        "    print(f'### train size {len(train_index)}, valid size {len(valid_index)}')\n",
        "    print('#'*25)\n",
        "\n",
        "    K.clear_session()\n",
        "    with strategy.scope():\n",
        "        model = build_model()\n",
        "        # model = build_MixNet_model(36,1,1,1,1)\n",
        "        model.fit(train_gen, verbose=1,\n",
        "              validation_data = valid_gen,\n",
        "              epochs=EPOCHS, callbacks = [LR] )\n",
        "        model.save_weights(f'Mixnet_36_1_1_1_1_f{i}_computed_specs.h5')\n",
        "\n",
        "    oof = model.predict(valid_gen, verbose=1)\n",
        "    all_oof.append(oof)\n",
        "    all_true.append(train.iloc[valid_index][TARGETS].values)\n",
        "\n",
        "    del model, oof\n",
        "    gc.collect()\n",
        "\n",
        "all_oof = np.concatenate(all_oof)\n",
        "all_true = np.concatenate(all_true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ZBsvYupsolG"
      },
      "outputs": [],
      "source": [
        "# np.save(\"all_oof.npy\", all_oof )\n",
        "# save_file_to_drive(\"all_oof.npy\",\"all_oof.npy\")\n",
        "# np.save(\"all_true.npy\", all_true )\n",
        "# save_file_to_drive(\"all_true.npy\",\"all_true.npy\")\n",
        "\n",
        "for i in range(5):\n",
        "  save_file_to_drive(f'Mixnet_50_6_12_20_12_f{i}_computed_specs.h5',f'Mixnet_36_1_1_1_1_f{i}_computed_specs.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIVB2ZXHsBPf"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This script exists to reduce code duplication across metrics.\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas.api.types\n",
        "\n",
        "from typing import Union\n",
        "\n",
        "\n",
        "class ParticipantVisibleError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "class HostVisibleError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def treat_as_participant_error(error_message: str, solution: Union[pd.DataFrame, np.ndarray]) -> bool:\n",
        "    ''' Many metrics can raise more errors than can be handled manually. This function attempts\n",
        "    to identify errors that can be treated as ParticipantVisibleError without leaking any competition data.\n",
        "\n",
        "    If the solution is purely numeric, and there are no numbers in the error message,\n",
        "    then the error message is sufficiently unlikely to leak usable data and can be shown to participants.\n",
        "\n",
        "    We expect this filter to reject many safe messages. It's intended only to reduce the number of errors we need to manage manually.\n",
        "    '''\n",
        "    # This check treats bools as numeric\n",
        "    if isinstance(solution, pd.DataFrame):\n",
        "        solution_is_all_numeric = all([pandas.api.types.is_numeric_dtype(x) for x in solution.dtypes.values])\n",
        "        solution_has_bools = any([pandas.api.types.is_bool_dtype(x) for x in solution.dtypes.values])\n",
        "    elif isinstance(solution, np.ndarray):\n",
        "        solution_is_all_numeric = pandas.api.types.is_numeric_dtype(solution)\n",
        "        solution_has_bools = pandas.api.types.is_bool_dtype(solution)\n",
        "\n",
        "    if not solution_is_all_numeric:\n",
        "        return False\n",
        "\n",
        "    for char in error_message:\n",
        "        if char.isnumeric():\n",
        "            return False\n",
        "    if solution_has_bools:\n",
        "        if 'true' in error_message.lower() or 'false' in error_message.lower():\n",
        "            return False\n",
        "    return True\n",
        "\n",
        "\n",
        "def safe_call_score(metric_function, solution, submission, **metric_func_kwargs):\n",
        "    '''\n",
        "    Call score. If that raises an error and that already been specifically handled, just raise it.\n",
        "    Otherwise make a conservative attempt to identify potential participant visible errors.\n",
        "    '''\n",
        "    try:\n",
        "        score_result = metric_function(solution, submission, **metric_func_kwargs)\n",
        "    except Exception as err:\n",
        "        error_message = str(err)\n",
        "        if err.__class__.__name__ == 'ParticipantVisibleError':\n",
        "            raise ParticipantVisibleError(error_message)\n",
        "        elif err.__class__.__name__ == 'HostVisibleError':\n",
        "            raise HostVisibleError(error_message)\n",
        "        else:\n",
        "            if treat_as_participant_error(error_message, solution):\n",
        "                raise ParticipantVisibleError(error_message)\n",
        "            else:\n",
        "                raise err\n",
        "    return score_result\n",
        "\n",
        "\n",
        "def verify_valid_probabilities(df: pd.DataFrame, df_name: str):\n",
        "    \"\"\" Verify that the dataframe contains valid probabilities.\n",
        "\n",
        "    The dataframe must be limited to the target columns; do not pass in any ID columns.\n",
        "    \"\"\"\n",
        "    if not pandas.api.types.is_numeric_dtype(df.values):\n",
        "        raise ParticipantVisibleError(f'All target values in {df_name} must be numeric')\n",
        "\n",
        "    if df.min().min() < 0:\n",
        "        raise ParticipantVisibleError(f'All target values in {df_name} must be at least zero')\n",
        "\n",
        "    if df.max().max() > 1:\n",
        "        raise ParticipantVisibleError(f'All target values in {df_name} must be no greater than one')\n",
        "\n",
        "    if not np.allclose(df.sum(axis=1), 1):\n",
        "        raise ParticipantVisibleError(f'Target values in {df_name} do not add to one within all rows')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3HlmURBrpM9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas.api.types\n",
        "\n",
        "from typing import Optional\n",
        "\n",
        "\n",
        "class ParticipantVisibleError(Exception):\n",
        "    pass\n",
        "\n",
        "\n",
        "def kl_divergence(solution: pd.DataFrame, submission: pd.DataFrame, epsilon: float, micro_average: bool, sample_weights: Optional[pd.Series]):\n",
        "    # Overwrite solution for convenience\n",
        "    for col in solution.columns:\n",
        "        # Prevent issue with populating int columns with floats\n",
        "        if not pandas.api.types.is_float_dtype(solution[col]):\n",
        "            solution[col] = solution[col].astype(float)\n",
        "\n",
        "        # Clip both the min and max following Kaggle conventions for related metrics like log loss\n",
        "        # Clipping the max avoids cases where the loss would be infinite or undefined, clipping the min\n",
        "        # prevents users from playing games with the 20th decimal place of predictions.\n",
        "        submission[col] = np.clip(submission[col], epsilon, 1 - epsilon)\n",
        "\n",
        "        y_nonzero_indices = solution[col] != 0\n",
        "        solution[col] = solution[col].astype(float)\n",
        "        solution.loc[y_nonzero_indices, col] = solution.loc[y_nonzero_indices, col] * np.log(solution.loc[y_nonzero_indices, col] / submission.loc[y_nonzero_indices, col])\n",
        "        # Set the loss equal to zero where y_true equals zero following the scipy convention:\n",
        "        # https://docs.scipy.org/doc/scipy/reference/generated/scipy.special.rel_entr.html#scipy.special.rel_entr\n",
        "        solution.loc[~y_nonzero_indices, col] = 0\n",
        "\n",
        "    if micro_average:\n",
        "        return np.average(solution.sum(axis=1), weights=sample_weights)\n",
        "    else:\n",
        "        return np.average(solution.mean())\n",
        "\n",
        "\n",
        "def score(\n",
        "        solution: pd.DataFrame,\n",
        "        submission: pd.DataFrame,\n",
        "        row_id_column_name: str,\n",
        "        epsilon: float=10**-15,\n",
        "        micro_average: bool=True,\n",
        "        sample_weights_column_name: Optional[str]=None\n",
        "    ) -> float:\n",
        "    del solution[row_id_column_name]\n",
        "    del submission[row_id_column_name]\n",
        "\n",
        "    sample_weights = None\n",
        "    if sample_weights_column_name:\n",
        "        if sample_weights_column_name not in solution.columns:\n",
        "            raise ParticipantVisibleError(f'{sample_weights_column_name} not found in solution columns')\n",
        "        sample_weights = solution.pop(sample_weights_column_name)\n",
        "\n",
        "    if sample_weights_column_name and not micro_average:\n",
        "        raise ParticipantVisibleError('Sample weights are only valid if `micro_average` is `True`')\n",
        "\n",
        "    for col in solution.columns:\n",
        "        if col not in submission.columns:\n",
        "            raise ParticipantVisibleError(f'Missing submission column {col}')\n",
        "\n",
        "    verify_valid_probabilities(solution, 'solution')\n",
        "    verify_valid_probabilities(submission, 'submission')\n",
        "\n",
        "\n",
        "    return safe_call_score(kl_divergence, solution, submission, epsilon=epsilon, micro_average=micro_average, sample_weights=sample_weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFucagk2t_XU",
        "outputId": "c4b1ab4a-2e33-458f-e0ed-423ded15c43c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CV Score KL-Div for Model = 0.7879304284147362\n"
          ]
        }
      ],
      "source": [
        "oof = pd.DataFrame(all_oof.copy())\n",
        "oof['id'] = np.arange(len(oof))\n",
        "\n",
        "true = pd.DataFrame(all_true.copy())\n",
        "true['id'] = np.arange(len(true))\n",
        "\n",
        "cv = score(solution=true, submission=oof, row_id_column_name='id')\n",
        "print('CV Score KL-Div for Model =',cv)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8yLQEtXTesD"
      },
      "source": [
        "# Display Grad Cam\n",
        "With grad cam, given a specific OOF (out of fold) train sample, we can view both a model's prediction and where it looked to make this prediction. In the plots below we display the image that was fed into our image model, in my popular starter notebook, there are 8 spectrograms that have been tiled into one 1 input image.\n",
        "\n",
        "On the left we have the 4 Kaggle spectrograms where each is 10 minutes long. Each represents one of the 4 montages LL, RL, LP, RP. (Montages explained [here][1]) On the right, we have the 4 EEG spectrograms where each is 50 seconds long. The EEG spectrograms are made from the Magic Formula [here][2]. The spectrograms are each `128x256x1`, so the final concatenation is `512x512x1`.\n",
        "\n",
        "![](https://raw.githubusercontent.com/cdeotte/Kaggle_Images/main/Feb-2024/key2.png)\n",
        "\n",
        "Each plot below has 3 subplots. The middle and right subplot use the KEY above. The left subplot is just the Grad Cam image where larger values (more yellow) indicates more attention. The middle subplot is the contours of the Grad Cam's 10% largest values superimposed over the image that we fed into our model. The right subplot is also Grad Cam contour superimposed over image but we add an emboss filter to the image to make the details more visible to humans. For explanations about specific grad cam examples, see discussion [here][3]\n",
        "\n",
        "[1]: https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/467877\n",
        "[2]: https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/469760\n",
        "[3]: https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/472976"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2024-02-03T02:42:19.551759Z",
          "iopub.status.busy": "2024-02-03T02:42:19.551463Z",
          "iopub.status.idle": "2024-02-03T02:42:19.561052Z",
          "shell.execute_reply": "2024-02-03T02:42:19.560018Z",
          "shell.execute_reply.started": "2024-02-03T02:42:19.551734Z"
        },
        "id": "_HoOH6eiTesD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "# HELPER FUNCTION\n",
        "def mask2contour(mask, width=5):\n",
        "    w = mask.shape[1]\n",
        "    h = mask.shape[0]\n",
        "    mask2 = np.concatenate([mask[:,width:],np.zeros((h,width))],axis=1)\n",
        "    mask2 = np.logical_xor(mask,mask2)\n",
        "    mask3 = np.concatenate([mask[width:,:],np.zeros((width,w))],axis=0)\n",
        "    mask3 = np.logical_xor(mask,mask3)\n",
        "    return np.logical_or(mask2,mask3)\n",
        "\n",
        "clahe = cv2.createCLAHE(clipLimit=16.0, tileGridSize=(8,8))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-input": true,
        "execution": {
          "iopub.execute_input": "2024-02-03T02:42:19.562809Z",
          "iopub.status.busy": "2024-02-03T02:42:19.562522Z",
          "iopub.status.idle": "2024-02-03T02:43:42.794885Z",
          "shell.execute_reply": "2024-02-03T02:43:42.793849Z",
          "shell.execute_reply.started": "2024-02-03T02:42:19.562785Z"
        },
        "id": "DjL5K-ChTesD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "BATCH = 128\n",
        "\n",
        "for ii,tt in enumerate(TARGETS):\n",
        "    ttt = tt.split('_')[0].upper()\n",
        "\n",
        "    print()\n",
        "    print('#'*25)\n",
        "    print('###',tt.upper())\n",
        "    print('#'*25)\n",
        "\n",
        "    # FIND TRAIN SAMPLES IN OOF (OUT OF FOLD) WITH TARGET >= 0.5\n",
        "    IDX = train.loc[train.index.isin(valid_index) & (train[tt]>=0.5),TARGETS].index.values\n",
        "    print(f'Found {len(IDX)} samples in fold zero OOF for {tt} with true>0.5')\n",
        "\n",
        "    # INFER TRAIN SAMPLES WITH MODEL (SAVE PREDS AND ACTIVATIONS)\n",
        "    valid_gen = DataGenerator(train.iloc[IDX[:128]], shuffle=False, batch_size=BATCH, mode='valid')\n",
        "    p,xx = model.predict(valid_gen,verbose=0)\n",
        "    #print(xx.shape)\n",
        "\n",
        "    # DISPLAY GRAD CAM\n",
        "    for x,y in valid_gen:\n",
        "        ct = 0\n",
        "        for i in range(BATCH):\n",
        "\n",
        "            # FIND SAMPLES WITH PRED >= 0.5 FOR TARGET\n",
        "            if i>=len(p): continue\n",
        "            pred = p[i]\n",
        "            if pred[ii]<0.5: continue\n",
        "\n",
        "            # FORMAT PREDICTIONS AS STRING\n",
        "            pred2 = ''; true2 = ''\n",
        "            true = train.loc[IDX[i]][TARGETS].values\n",
        "            for j,t in enumerate(TARGETS):\n",
        "                n = t.split('_')[0]\n",
        "                pred2 += f' {n}={pred[j]:0.3f}'\n",
        "                true2 += f' {n}={true[j]:0.3f}'\n",
        "            print()\n",
        "            print('==> TRUE:',true2)\n",
        "            print('==> PRED:',pred2)\n",
        "\n",
        "            # PLOT GRAD CAM RESULTS\n",
        "            plt.figure(figsize=(20,8))\n",
        "\n",
        "            # PLOT GRAD CAM IMAGE (PLOT 1 OF 3)\n",
        "            plt.subplot(1,3,1)\n",
        "            img = np.sum(xx[i,] * layer_weights,axis=-1)\n",
        "            img = cv2.resize(img,(512,512))\n",
        "            plt.imshow(img[::-1,])\n",
        "            plt.title(f'{ttt} - Grad Cam',size=14)\n",
        "\n",
        "            # FIND GRAD CAM CONTOURS FOR AREAS OF INTEREST\n",
        "            cut = np.percentile(img.flatten(), [90])[0]\n",
        "            cntr = img.copy()\n",
        "            cntr[cntr>=cut] = 100\n",
        "            cntr[cntr<cut] = 0\n",
        "            cntr = mask2contour(cntr)\n",
        "\n",
        "            # PLOT EMBOSSED SPECTROGRAMS WITH GRADCAM CONTOURS (PLOT 3 OF 3)\n",
        "            plt.subplot(1,3,3)\n",
        "            x1 = [x[i,:,:,k:k+1] for k in range(4)] #KAGGLE-SPECS: LL RL LP RP\n",
        "            x1 = np.concatenate(x1,axis=0)\n",
        "            x2 = [x[i,:,:,k+4:k+5] for k in range(4)] #EEG-SPECS: LL LP RL RP\n",
        "            x2 = np.concatenate(x2,axis=0)\n",
        "            x3 = np.concatenate([x1,x2],axis=1)\n",
        "            img = cv2.resize(x3,(512,512))\n",
        "            img0 = img.copy()\n",
        "\n",
        "            # EMBOSS IMAGE FOR IMAGE FEATURE VISIBILITY\n",
        "            img = img[1:,1:] - img[:-1,:-1] #emboss\n",
        "            img -= np.min(img)\n",
        "            img /= np.max(img)\n",
        "            img = (img*255).astype('uint8')\n",
        "            img = cv2.GaussianBlur(img,(5,5),0)\n",
        "            img = clahe.apply(img)\n",
        "            mx = np.max(img)\n",
        "\n",
        "            cntr2 = cntr[1:,1:]\n",
        "            img[cntr2>0] = mx\n",
        "            plt.imshow(img[::-1,])\n",
        "            plt.title(f'{ttt} - Embossed Spectrogram with Grad Cam Contours',size=14)\n",
        "\n",
        "            # PLOT SPECTROGRAMS WITH GRADCAM CONTOURS (PLOT 2 OF 3)\n",
        "            plt.subplot(1,3,2)\n",
        "            mx = np.max(img0)\n",
        "            img0[cntr>0] = mx\n",
        "            plt.imshow(img0[::-1,])\n",
        "            plt.title(f'{ttt} - Spectrogram with Grad Cam Contours',size=14)\n",
        "\n",
        "            plt.show()\n",
        "            ct += 1\n",
        "            if ct==8: break\n",
        "\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38MsL9Xm-1GC"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "3u8Qj_9aXZSZ",
        "b7b-WWutTesC"
      ],
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "databundleVersionId": 7469972,
          "sourceId": 59093,
          "sourceType": "competition"
        },
        {
          "datasetId": 4297782,
          "sourceId": 7392775,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4304475,
          "sourceId": 7402356,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4334995,
          "sourceId": 7447509,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4336944,
          "sourceId": 7450712,
          "sourceType": "datasetVersion"
        },
        {
          "sourceId": 158958765,
          "sourceType": "kernelVersion"
        }
      ],
      "dockerImageVersionId": 30648,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
